{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Problem2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python389jvsc74a57bd0a521ea166c522efd727cf1be1d8ee30880aa7d991c97036f1a0fca5594a114b9",
      "display_name": "Python 3.8.9 64-bit ('.venv')"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.9"
    },
    "metadata": {
      "interpreter": {
        "hash": "a521ea166c522efd727cf1be1d8ee30880aa7d991c97036f1a0fca5594a114b9"
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8EhSG3Zj7zqA"
      },
      "source": [
        "3) The original model size is 10.7MB and the compressed model is 8.5MB. **It is 2MB smaller.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ujYsE_FkX0Xb"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import os\n",
        "import PIL.Image as Image\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pkz21xyKEXbs"
      },
      "source": [
        "path_to_model_folder = \"saved_models/\"\n",
        "path_to_dataset_folder = \"dataset/\""
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C2eQrCBDYBT-"
      },
      "source": [
        "# Convert the model (let's use the saved model from the previous exercise)\n",
        "converter = tf.lite.TFLiteConverter.from_saved_model(path_to_model_folder + \"model_1\") # path to the SavedModel directory\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "\n",
        "# Save the model\n",
        "with open(path_to_model_folder + \"model_1.tflite\", 'wb') as f:\n",
        "  f.write(tflite_model)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2bTmVaZ7k8r3"
      },
      "source": [
        "IMAGE_SHAPE = (224, 224)\n",
        "\n",
        "interpreter = tf.lite.Interpreter(model_content=tflite_model)\n",
        "interpreter.allocate_tensors()\n",
        "\n",
        "input_details = interpreter.get_input_details()\n",
        "output_details = interpreter.get_output_details()\n",
        "\n",
        "input_shape = input_details[0]['shape']\n",
        "\n",
        "img01 = Image.open(path_to_dataset_folder + \"Test/00243.png\").resize(IMAGE_SHAPE)\n",
        "img01 = np.array(img01, dtype=np.float32)/255.0\n",
        "img02 = Image.open(path_to_dataset_folder + \"Test/00252.png\").resize(IMAGE_SHAPE)\n",
        "img02 = np.array(img02, dtype=np.float32)/255.0\n",
        "\n",
        "img11 = Image.open(path_to_dataset_folder + \"Test/00001.png\").resize(IMAGE_SHAPE)\n",
        "img11 = np.array(img11, dtype=np.float32)/255.0\n",
        "img12 = Image.open(path_to_dataset_folder + \"Test/00091.png\").resize(IMAGE_SHAPE)\n",
        "img12 = np.array(img12, dtype=np.float32)/255.0\n",
        "\n",
        "img21 = Image.open(path_to_dataset_folder + \"Test/00034.png\").resize(IMAGE_SHAPE)\n",
        "img21 = np.array(img21, dtype=np.float32)/255.0\n",
        "img22 = Image.open(path_to_dataset_folder + \"Test/00067.png\").resize(IMAGE_SHAPE)\n",
        "img22 = np.array(img22, dtype=np.float32)/255.0\n",
        "\n",
        "img31 = Image.open(path_to_dataset_folder + \"Test/00023.png\").resize(IMAGE_SHAPE)\n",
        "img31 = np.array(img31, dtype=np.float32)/255.0\n",
        "img32 = Image.open(path_to_dataset_folder + \"Test/00086.png\").resize(IMAGE_SHAPE)\n",
        "img32 = np.array(img32, dtype=np.float32)/255.0\n",
        "\n",
        "img41 = Image.open(path_to_dataset_folder + \"Test/00014.png\").resize(IMAGE_SHAPE)\n",
        "img41 = np.array(img41, dtype=np.float32)/255.0\n",
        "img42 = Image.open(path_to_dataset_folder + \"Test/00020.png\").resize(IMAGE_SHAPE)\n",
        "img42 = np.array(img42, dtype=np.float32)/255.0"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bivYAi-m8sZ_"
      },
      "source": [
        "4) It take **less than a 1 second** to classify an image."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gLcjEQpcCswM"
      },
      "source": [
        "5) We did not find how to pass a folder to an interpreter, we therefore only tried on 2 images of each class we trained.\n",
        "\n",
        "On 10 test we have 6 correct predictions and 4 incorect. We can say that we have a lower accuracy with a compressed model. (accuracy ~= 0.6) "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2RGF93Jv5lcH",
        "outputId": "73ef5af7-7705-424f-9bc1-664e089c537f"
      },
      "source": [
        "interpreter.set_tensor(input_details[0]['index'], np.array(img01[np.newaxis, ...]))\n",
        "interpreter.invoke()\n",
        "output_data = interpreter.get_tensor(output_details[0]['index'])\n",
        "print(\"Class 0: \", output_data)\n",
        "\n",
        "interpreter.set_tensor(input_details[0]['index'], np.array(img02[np.newaxis, ...]))\n",
        "interpreter.invoke()\n",
        "output_data = interpreter.get_tensor(output_details[0]['index'])\n",
        "print(\"Class 0: \", output_data)\n",
        "\n",
        "interpreter.set_tensor(input_details[0]['index'], np.array(img11[np.newaxis, ...]))\n",
        "interpreter.invoke()\n",
        "output_data = interpreter.get_tensor(output_details[0]['index'])\n",
        "print(\"Class 1: \", output_data)\n",
        "\n",
        "interpreter.set_tensor(input_details[0]['index'], np.array(img12[np.newaxis, ...]))\n",
        "interpreter.invoke()\n",
        "output_data = interpreter.get_tensor(output_details[0]['index'])\n",
        "print(\"Class 1: \", output_data)\n",
        "\n",
        "interpreter.set_tensor(input_details[0]['index'], np.array(img21[np.newaxis, ...]))\n",
        "interpreter.invoke()\n",
        "output_data = interpreter.get_tensor(output_details[0]['index'])\n",
        "print(\"Class 2: \", output_data)\n",
        "\n",
        "interpreter.set_tensor(input_details[0]['index'], np.array(img22[np.newaxis, ...]))\n",
        "interpreter.invoke()\n",
        "output_data = interpreter.get_tensor(output_details[0]['index'])\n",
        "print(\"Class 2: \", output_data)\n",
        "\n",
        "interpreter.set_tensor(input_details[0]['index'], np.array(img31[np.newaxis, ...]))\n",
        "interpreter.invoke()\n",
        "output_data = interpreter.get_tensor(output_details[0]['index'])\n",
        "print(\"Class 3: \", output_data)\n",
        "\n",
        "interpreter.set_tensor(input_details[0]['index'], np.array(img32[np.newaxis, ...]))\n",
        "interpreter.invoke()\n",
        "output_data = interpreter.get_tensor(output_details[0]['index'])\n",
        "print(\"Class 3: \", output_data)\n",
        "\n",
        "interpreter.set_tensor(input_details[0]['index'], np.array(img41[np.newaxis, ...]))\n",
        "interpreter.invoke()\n",
        "output_data = interpreter.get_tensor(output_details[0]['index'])\n",
        "print(\"Class 4: \", output_data)\n",
        "\n",
        "interpreter.set_tensor(input_details[0]['index'], np.array(img42[np.newaxis, ...]))\n",
        "interpreter.invoke()\n",
        "output_data = interpreter.get_tensor(output_details[0]['index'])\n",
        "print(\"Class 4: \", output_data)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class 0:  [[-5.3667893  0.5580664  1.6177809 -5.4882894 -4.409288 ]]\n",
            "Class 0:  [[-2.7627206  -0.9083447  -0.47687778 -4.6684175   0.04632676]]\n",
            "Class 1:  [[-6.210735   4.9142923 -1.2545431 -4.835281  -4.540983 ]]\n",
            "Class 1:  [[-1.6362742  5.7482605  0.6390624 -5.1277575 -6.400246 ]]\n",
            "Class 2:  [[-4.7747903 -4.4608865  2.710119  -1.876615  -2.5938637]]\n",
            "Class 2:  [[-7.1462727   0.37163547 -1.2618643   0.3442396  -1.8246096 ]]\n",
            "Class 3:  [[-13.563831    -0.43298003  -2.0357323    4.7743235   -7.2821407 ]]\n",
            "Class 3:  [[-8.56211    -4.3033285  -0.71174014  2.7926698  -1.4955043 ]]\n",
            "Class 4:  [[-5.5198994  -0.5329679   0.72670853 -6.7100286  -2.1167383 ]]\n",
            "Class 4:  [[-9.847571   -1.8688519  -0.83252734 -4.033246    1.4620259 ]]\n"
          ]
        }
      ]
    }
  ]
}